{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4a9086-f008-416e-a1e1-6d81e9d04a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Change the plotting style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "## =============================================\n",
    "## 1. Core Gradient Descent Implementation\n",
    "## =============================================\n",
    "\n",
    "def gradient_descent(f, grad_f, x0, alpha_type='fixed', alpha=0.01, \n",
    "                    max_steps=1000, tolerance=0.0001, \n",
    "                    c1=1e-4, rho=0.5, max_line_search_iter=20):\n",
    "    \"\"\"\n",
    "    Gradient descent optimization algorithm.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    f : function\n",
    "        The objective function to minimize.\n",
    "    grad_f : function\n",
    "        The gradient of the objective function.\n",
    "    x0 : numpy array\n",
    "        The starting point.\n",
    "    alpha_type : str\n",
    "        Type of step size: 'fixed' or 'backtracking'.\n",
    "    alpha : float\n",
    "        Initial step size.\n",
    "    max_steps : int\n",
    "        Maximum number of iterations.\n",
    "    tolerance : float\n",
    "        Convergence tolerance.\n",
    "    c1 : float\n",
    "        Parameter for Armijo condition.\n",
    "    rho : float\n",
    "        Reduction factor for backtracking.\n",
    "    max_line_search_iter : int\n",
    "        Maximum backtracking iterations.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    X : numpy array\n",
    "        Final solution point.\n",
    "    f_values : list\n",
    "        Function values at each iteration.\n",
    "    path : list\n",
    "        The optimization path.\n",
    "    steps : int\n",
    "        Number of steps taken.\n",
    "    \"\"\"\n",
    "    X = np.array(x0, dtype='float64')\n",
    "    path = [X.copy()]\n",
    "    f_values = [f(X)]\n",
    "    \n",
    "    for step in range(max_steps):\n",
    "        grad = grad_f(X)\n",
    "        \n",
    "        # Determine step size\n",
    "        if alpha_type == 'backtracking':\n",
    "            current_alpha = alpha\n",
    "            for _ in range(max_line_search_iter):\n",
    "                X_new = X - current_alpha * grad\n",
    "                # Armijo condition\n",
    "                if f(X_new) <= f(X) + c1 * current_alpha * np.dot(grad, -grad):\n",
    "                    break\n",
    "                current_alpha *= rho\n",
    "            alpha_used = current_alpha\n",
    "        else:\n",
    "            alpha_used = alpha\n",
    "        \n",
    "        # Update position\n",
    "        X_new = X - alpha_used * grad\n",
    "        \n",
    "        # Check for convergence\n",
    "        if np.linalg.norm(X_new - X) < tolerance:\n",
    "            break\n",
    "            \n",
    "        X = X_new\n",
    "        path.append(X.copy())\n",
    "        f_values.append(f(X))\n",
    "    \n",
    "    return X, f_values, path, step+1\n",
    "\n",
    "## =============================================\n",
    "## 2. Visualization Functions\n",
    "## =============================================\n",
    "\n",
    "def plot_function_3d(f, x_range=(-5, 5), y_range=(-5, 5), title=\"\"):\n",
    "    \"\"\"Create a 3D surface plot of the function.\"\"\"\n",
    "    x = np.linspace(x_range[0], x_range[1], 100)\n",
    "    y = np.linspace(y_range[0], y_range[1], 100)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    Z = f([X, Y])\n",
    "    \n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    surf = ax.plot_surface(X, Y, Z, cmap=cm.coolwarm, alpha=0.8)\n",
    "    fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_zlabel('f(x,y)')\n",
    "    ax.set_title(title)\n",
    "    plt.show()\n",
    "\n",
    "def plot_contour(f, x_range=(-5, 5), y_range=(-5, 5), title=\"\"):\n",
    "    \"\"\"Create a contour plot of the function.\"\"\"\n",
    "    x = np.linspace(x_range[0], x_range[1], 100)\n",
    "    y = np.linspace(y_range[0], y_range[1], 100)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    Z = f([X, Y])\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.contour(X, Y, Z, levels=50)\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "def plot_convergence_path(f, path, title, x_range=(-5, 5), y_range=(-5, 5)):\n",
    "    \"\"\"Plot the optimization path on a contour plot.\"\"\"\n",
    "    x = np.linspace(x_range[0], x_range[1], 100)\n",
    "    y = np.linspace(y_range[0], y_range[1], 100)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    Z = f([X, Y])\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.contour(X, Y, Z, levels=50)\n",
    "    plt.colorbar()\n",
    "    \n",
    "    # Plot path\n",
    "    path_array = np.array(path)\n",
    "    plt.plot(path_array[:, 0], path_array[:, 1], 'r.-', markersize=10)\n",
    "    plt.scatter(path_array[0, 0], path_array[0, 1], c='green', s=100, label='Start')\n",
    "    plt.scatter(path_array[-1, 0], path_array[-1, 1], c='blue', s=100, label='End')\n",
    "    \n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def plot_convergence_values(f_values, title):\n",
    "    \"\"\"Plot the function values during optimization.\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(f_values, 'b-', linewidth=2)\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Function Value')\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "## =============================================\n",
    "## 3. Test Functions and Their Gradients\n",
    "## =============================================\n",
    "\n",
    "# 1. Original function\n",
    "def f1(X):\n",
    "    x, y = X\n",
    "    return (x-47)**2 + (y-0.1)**2 + 2\n",
    "\n",
    "def grad_f1(X):\n",
    "    x, y = X\n",
    "    return np.array([2*(x-47), 2*(y-0.1)])\n",
    "\n",
    "# 2. Rosenbrock function (n=5)\n",
    "def rosenbrock(X):\n",
    "    return sum(100*(X[i+1]-X[i]**2)**2 + (1-X[i])**2 for i in range(len(X)-1))\n",
    "\n",
    "def grad_rosenbrock(X):\n",
    "    n = len(X)\n",
    "    grad = np.zeros(n)\n",
    "    for i in range(n-1):\n",
    "        grad[i] += -400*X[i]*(X[i+1]-X[i]**2) - 2*(1-X[i])\n",
    "        grad[i+1] += 200*(X[i+1]-X[i]**2)\n",
    "    return grad\n",
    "\n",
    "# 3. Booth function\n",
    "def booth(X):\n",
    "    x, y = X\n",
    "    return (x + 2*y - 7)**2 + (2*x + y - 5)**2\n",
    "\n",
    "def grad_booth(X):\n",
    "    x, y = X\n",
    "    return np.array([\n",
    "        2*(x + 2*y - 7) + 4*(2*x + y - 5),\n",
    "        4*(x + 2*y - 7) + 2*(2*x + y - 5)\n",
    "    ])\n",
    "\n",
    "# 4. Himmelblau's function\n",
    "def himmelblau(X):\n",
    "    x, y = X\n",
    "    return (x**2 + y - 11)**2 + (x + y**2 - 7)**2\n",
    "\n",
    "def grad_himmelblau(X):\n",
    "    x, y = X\n",
    "    return np.array([\n",
    "        4*x*(x**2 + y - 11) + 2*(x + y**2 - 7),\n",
    "        2*(x**2 + y - 11) + 4*y*(x + y**2 - 7)\n",
    "    ])\n",
    "\n",
    "# 5. Three-hump camel function\n",
    "def camel(X):\n",
    "    x, y = X\n",
    "    return 2*x**2 - 1.05*x**4 + x**6/6 + x*y + y**2\n",
    "\n",
    "def grad_camel(X):\n",
    "    x, y = X\n",
    "    return np.array([\n",
    "        4*x - 4.2*x**3 + x**5 + y,\n",
    "        x + 2*y\n",
    "    ])\n",
    "\n",
    "# 6. McCormick function\n",
    "def mccormick(X):\n",
    "    x, y = X\n",
    "    return np.sin(x + y) + (x - y)**2 - 1.5*x + 2.5*y + 1\n",
    "\n",
    "def grad_mccormick(X):\n",
    "    x, y = X\n",
    "    return np.array([\n",
    "        np.cos(x + y) + 2*(x - y) - 1.5,\n",
    "        np.cos(x + y) - 2*(x - y) + 2.5\n",
    "    ])\n",
    "\n",
    "## =============================================\n",
    "## 4. Testing and Visualization\n",
    "## =============================================\n",
    "\n",
    "def test_function(f, grad_f, name, test_cases):\n",
    "    \"\"\"Test gradient descent on a function with various parameters.\"\"\"\n",
    "    print(f\"\\n===== Testing {name} Function =====\")\n",
    "    \n",
    "    for i, case in enumerate(test_cases):\n",
    "        print(f\"\\nTest Case {i+1}:\")\n",
    "        print(f\"Initial point: {case['x0']}, Alpha: {case.get('alpha', 'backtracking')}\")\n",
    "        \n",
    "        # Extraia apenas os parÃ¢metros esperados pela gradient_descent\n",
    "        valid_keys = ['x0', 'alpha_type', 'alpha', 'max_steps', 'tolerance', 'c1', 'rho', 'max_line_search_iter']\n",
    "        gd_params = {k: v for k, v in case.items() if k in valid_keys}\n",
    "        \n",
    "        # Executa o gradiente descendente\n",
    "        result = gradient_descent(f, grad_f, **gd_params)\n",
    "        X_opt, f_values, path, steps = result\n",
    "        \n",
    "        print(f\"Optimal point: {X_opt}\")\n",
    "        print(f\"Steps: {steps}, Final value: {f_values[-1]}\")\n",
    "        \n",
    "        # Se o ponto inicial for 2D, plota os resultados\n",
    "        if len(case['x0']) == 2:\n",
    "            plot_convergence_path(\n",
    "                f, path, \n",
    "                f\"{name} Function - Path (Case {i+1})\",\n",
    "                x_range=case.get('x_range', (-5,5)),\n",
    "                y_range=case.get('y_range', (-5,5))\n",
    "            )\n",
    "            plot_convergence_values(\n",
    "                f_values, \n",
    "                f\"{name} Function - Convergence (Case {i+1})\"\n",
    "            )\n",
    "\n",
    "# Define test cases for each function\n",
    "test_cases_f1 = [\n",
    "    {'x0': [80, 20], 'alpha_type': 'fixed', 'alpha': 0.5, 'x_range': (0,100), 'y_range': (-20,40)},\n",
    "    {'x0': [80, 20], 'alpha_type': 'backtracking', 'alpha': 1.0, 'x_range': (0,100), 'y_range': (-20,40)}\n",
    "]\n",
    "\n",
    "test_cases_rosenbrock = [\n",
    "    {'x0': np.zeros(5), 'alpha_type': 'fixed', 'alpha': 0.0001, 'max_steps': 10000},\n",
    "    {'x0': np.ones(5), 'alpha_type': 'backtracking', 'alpha': 1.0, 'max_steps': 10000}\n",
    "]\n",
    "\n",
    "test_cases_booth = [\n",
    "    {'x0': [0, 0], 'alpha_type': 'fixed', 'alpha': 0.01, 'x_range': (-10,10), 'y_range': (-10,10)},\n",
    "    {'x0': [0, 0], 'alpha_type': 'fixed', 'alpha': 0.05, 'x_range': (-10,10), 'y_range': (-10,10)},\n",
    "    {'x0': [0, 0], 'alpha_type': 'backtracking', 'alpha': 1.0, 'x_range': (-10,10), 'y_range': (-10,10)}\n",
    "]\n",
    "\n",
    "test_cases_himmelblau = [\n",
    "    {'x0': [0, 0], 'alpha_type': 'fixed', 'alpha': 0.01, 'x_range': (-5,5), 'y_range': (-5,5)},\n",
    "    {'x0': [3, 3], 'alpha_type': 'fixed', 'alpha': 0.01, 'x_range': (-5,5), 'y_range': (-5,5)},\n",
    "    {'x0': [-3, -3], 'alpha_type': 'backtracking', 'alpha': 1.0, 'x_range': (-5,5), 'y_range': (-5,5)}\n",
    "]\n",
    "\n",
    "test_cases_camel = [\n",
    "    {'x0': [1, 1], 'alpha_type': 'fixed', 'alpha': 0.01, 'x_range': (-2,2), 'y_range': (-2,2)},\n",
    "    {'x0': [1, 1], 'alpha_type': 'backtracking', 'alpha': 1.0, 'x_range': (-2,2), 'y_range': (-2,2)}\n",
    "]\n",
    "\n",
    "test_cases_mccormick = [\n",
    "    {'x0': [-1, 2], 'alpha_type': 'fixed', 'alpha': 0.01, 'x_range': (-1.5,4), 'y_range': (-3,4)},\n",
    "    {'x0': [-1, 2], 'alpha_type': 'backtracking', 'alpha': 1.0, 'x_range': (-1.5,4), 'y_range': (-3,4)}\n",
    "]\n",
    "\n",
    "# Run tests\n",
    "if __name__ == \"__main__\":\n",
    "    test_function(f1, grad_f1, \"Original\", test_cases_f1)\n",
    "    test_function(rosenbrock, grad_rosenbrock, \"Rosenbrock\", test_cases_rosenbrock)\n",
    "    test_function(booth, grad_booth, \"Booth\", test_cases_booth)\n",
    "    test_function(himmelblau, grad_himmelblau, \"Himmelblau\", test_cases_himmelblau)\n",
    "    test_function(camel, grad_camel, \"Camel\", test_cases_camel)\n",
    "    test_function(mccormick, grad_mccormick, \"McCormick\", test_cases_mccormick)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
